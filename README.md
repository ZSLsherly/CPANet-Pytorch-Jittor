# CPANet-Jittor  
*(Jittor Implementation of [CPANet](https://ieeexplore.ieee.org/document/10049179) for Few-Shot Semantic Segmentation)*

[![Jittor](https://img.shields.io/badge/Jittor-1.3.9.14-blue)](https://cg.cs.tsinghua.edu.cn/jittor/)

---

## 📚 目录
- [项目简介](#项目简介)
- [环境配置](#环境配置)
- [数据集下载](#数据集下载)
- [运行脚本](#运行脚本)
- [实验复现](#实验复现)
  - [Backbone 对比实验](#backbone-对比实验)
  - [Loss 曲线](#loss-曲线)
- [消融实验](#消融实验)
- [参数消融](#参数消融)
- [遇到的问题](#遇到的问题)
- [总结](#总结)

---

## 📖 项目简介
本项目是 **CPANet** 在 [Jittor](https://cg.cs.tsinghua.edu.cn/jittor/) 框架下的复现版本，面向 Few-Shot Semantic Segmentation 任务，提供了可复现的训练、测试和消融实验。

---

## ⚙ 环境配置
```bash
CUDA==11.3
python==3.8.10
jittor==1.3.10
```

## ⚙ 数据集下载
您可以在 https://pan.baidu.com/s/1MQ5SwmDvPj-m3HxwmCTV3A?pwd=kezh 上下载数据集FSSD-12

## ⚙ 运行脚本
```bash
python train.py --config config/SSD/fold0_vgg16.yaml
python train.py --config config/SSD/fold0_resnet50.yaml
```

## ⚙ 实验复现

由于原作者未公开其 **ResNet 变体 Backbone**，本实验统一采用 **ImageNet 预训练的标准 ResNet**。  
在消融实验中，为了控制变量并便于对比，均以 **VGG-16** 作为 Backbone。  
所有实验均基于 **1-shot、fold-0** 数据集进行训练与评测。  

受模型架构与数据集规模限制，实验结果存在一定波动：  
- **VGG-16 Backbone** 下，mIoU 通常在 *0.52–0.54* 区间浮动  
- **ResNet-50 Backbone** 下，性能略低于原论文，可能与缺少其自定义 ResNet 变体有关

---

### 📊 Backbone 对比实验

#### 🔹 Jittor 版本（本复现）
| Backbone  | Method | mIoU (1-shot) | FB-IoU (1-shot) |
|-----------|--------|---------------|-----------------|
| VGG-16    | Ours   | **52.73**     | **69.78**       |
| ResNet-50 | Ours   | **58.07**     | **74.42**       |

#### 🔹 PyTorch 版本（原论文结果）
| Backbone  | Method | mIoU (1-shot) | FB-IoU (1-shot) |
|-----------|--------|---------------|-----------------|
| VGG-16    | Ours   | 50.80         | 69.10           |
| ResNet-50 | Ours   | 66.00         | 76.10           |

> 可以看出，在 VGG16 Backbone 下，Jittor 版本的性能与原论文基本一致；而在 ResNet50 上，mIoU 略低，可能与原作者自定义的 ResNet 变体有关。

---

### 📉 Loss 曲线

#### 训练集 Loss  
![Train Loss](train.png)

#### 测试集 Loss  
![Test Loss](test.png)


## ⚙ 消融实验

本部分对 **CPP**、**SA**、**SSA** 三个核心模块进行了消融分析，以验证各模块对模型性能的贡献。

- **CPP**：用掩码全局平均池化（GAP）替代。  
- **SA**：直接移除SA模块。  
- **SSA**：用全卷积解码器替代。

---

### 📊 模块消融实验结果（1-Shot）

#### 🔹 Jittor 版本（VGG-16 Backbone）
| CPP | SA  | SSA | mIoU (1-shot) | FB-IoU (1-shot) |
|:---:|:---:|:---:|:-------------:|:---------------:|
| ✓   | ✗   | ✗   | 42.30         | 64.26           |
| ✗   | ✓   | ✗   | 46.84         | 67.23           |
| ✗   | ✗   | ✓   | 52.89         | 72.19           |
| ✓   | ✓   | ✗   | 49.94         | 68.30           |
| ✗   | ✓   | ✓   | 53.64         | 71.27           |
| ✓   | ✗   | ✓   | 51.36         | 70.28           |
| ✓   | ✓   | ✓   | **54.05**     | **72.56**       |

#### 🔹 PyTorch 版本（原论文，ResNet-50 Backbone）
| CPP | SA  | SSA | mIoU (1-shot) | FB-IoU (1-shot) |
|:---:|:---:|:---:|:-------------:|:---------------:|
| ✗   | ✗   | ✗   | 57.70         | 71.40           |
| ✓   | ✗   | ✗   | 58.30         | 72.60           |
| ✓   | ✓   | ✗   | 65.80         | 75.90           |
| ✗   | ✗   | ✓   | 59.30         | 71.90           |
| ✓   | ✓   | ✓   | **66.00**     | **76.10**       |

---

### 📌 结果分析
- **SSA 模块** 对提升性能作用显著，单独加入时 mIoU 有明显提升。  
- **CPP 模块** 在 VGG16 Backbone 下单独使用时反而性能下降，但与其他模块结合可获得最佳效果。  
- **SA 模块** 与 CPP 结合后在 PyTorch 版本中提升显著，说明其在更强 Backbone 下的作用更明显。


## ⚙ 参数消融

超参数 **k** 用于控制总损失中主损失（L_main）与辅助损失（L_aux）的权重比。  
本节比较了不同 k 值（0.0, 0.2, 0.4, 0.6, 0.8, 1.0）下模型的最优性能表现。

---

### 📊 不同 k 值下的模型性能（1-Shot）

#### 🔹 Jittor 版本（VGG-16 Backbone）

| k    | mIoU (1-shot) | FB-IoU (1-shot) |
|:----:|:-------------:|:---------------:|
| 0.0  | 48.58         | 68.34           |
| 0.2  | 49.68         | 69.95           |
| 0.4  | **54.14**     | 70.63           |
| 0.6  | 48.29         | **70.09**       |
| 0.8  | 53.49         | 73.14           |
| 1.0  | 55.11         | 72.58           |

---

#### 🔹 PyTorch 版本（原论文，ResNet-50 Backbone）

| k    | mIoU (1-shot) | FB-IoU (1-shot) |
|:----:|:-------------:|:---------------:|
| 0.0  | 61.80         | 72.90           |
| 0.2  | 65.20         | 74.80           |
| 0.4  | **66.00**     | **76.10**       |
| 0.6  | 63.40         | 74.80           |
| 0.8  | 62.80         | 74.50           |
| 1.0  | 63.80         | 74.70           |

---

### 📌 结果分析

- Jittor 版本中，k=0.4 时模型取得最佳 mIoU 性能，FB-IoU 在 k=0.6 时略高。  
- PyTorch 版本与 Jittor 版本表现一致，k=0.4 是一个较优的权重平衡点。  
- 较大的 k 值（如 0.8 或 1.0）未能提升性能，可能因辅助损失权重过大影响主损失优化。  

综上，建议在训练时优先选择 k=0.4 以获得较稳定且较优的表现。

## ⚙ 遇到的问题

作为国内开源的深度学习框架，Jittor 的 API 与 PyTorch 等主流框架存在不少差异。整体来看，这些差异通过官方文档学习可以较快掌握和解决。  

我在复现过程中遇到的最大挑战是**环境配置**。  

最初，我使用 Python 3.7 + CUDA 12.6 环境，Jittor 自带测试用例和我实现的简单网络均能**正常收敛且通过测试**。  

然而，复现论文模型时出现训练异常，模型几乎不收敛且所有像素预测趋于同一值。  

起初怀疑是代码逻辑问题，反复查阅 GitHub issue、Jittor 论坛、CSDN 文章，并借助 AI 辅助排查。面对逻辑无误的代码，反复调试一周未果。  

最终通过**重新配置环境**（Python 3.8 + CUDA 11.3）解决了问题，训练正常恢复。  

---

## ⚙ 总结

本次实验基于 **Jittor 框架** 成功复现了 **CPANet** 的网络结构及训练流程。虽然整体实现完整，但复现效果与原论文仍存在一定差距，主要体现在性能指标上。

### 环境配置的重要性

对于新兴且相对年轻的深度学习框架（如 Jittor），环境配置尤为关键。  
应当严格遵循官方推荐的主流环境（Python 版本、CUDA 版本、依赖库版本），避免因环境差异导致难以定位的异常。  

### 收获与成长

- 深入理解了 CPANet 的模块设计与实现思路，深化了对 Few-Shot 语义分割关键技术的认识。  
- 掌握了 Jittor 框架的基础用法，包括数据加载、模型定义、训练与测试流程，熟悉了与 PyTorch 不同的接口及调试技巧。  
- 积累了复现深度学习模型的宝贵实践经验，为未来相关研究和工程项目奠定了坚实基础。

---

本实验虽有不足，但为基于 Jittor 框架复现复杂模型提供了宝贵经验与参考，期望能帮助更多研究者顺利开展相关工作。



